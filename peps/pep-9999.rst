PEP: 9999
Title: A package dependency name mapping mechanism
Author: Pradyun Gedam <pradyunsg@gmail.com>,
        Ralf Gommers <ralf.gommers@gmail.com>,
        Jaime Rodr√≠guez-Guerra <jrodriguez@quansight.com>,
        Michael Sarahan <msarahan@gmail.com>
Discussions-To:
Status: Draft
Type: Standards Track
Topic: Packaging
Created: 17-Aug-2023
Post-History: 17-Aug-2023,
Resolution:


Abstract
========

This PEP specifies a name mapping mechanism that allows packaging tools to map
external dependency identifiers (as introduced in :doc:`pep-0725`) to their
counterparts in other package repositories.

Motivation
==========

Packages on PyPI often require build-time and runtime dependencies that are not
present on PyPI. :doc:`pep-0725` introduced metadata to express
such dependencies. Using concrete external dependency metadata for
a Python package requires mapping the given dependency identifiers to the specifiers
used in other ecosystems.

In the context of external dependencies, there are at least two key motivators:

- Enabling tools to automatically map external dependencies to packages in other
  packaging repositories/ecosystems,
- Including the needed external dependencies *with the package
  names used by the relevant system package manager on the user's system* in
  error messages emitted by Python package installers and build frontends,
  as well as allowing the user to query for those names directly to obtain install
  instructions.

Packaging ecosystems like Linux distros, conda, Homebrew, Spack, and Nix need
full sets of dependencies for Python packages, and have tools like pyp2rpm_
(Fedora), Grayskull_ (conda), and dh_python_ (Debian) which attempt to
automatically generate dependency information from the metadata available in
upstream Python packages. Before PEP 725, external dependencies were handled manually,
because there was no metadata for this in ``pyproject.toml`` or any other
standard metadata file. Enabling its automatic conversion is a key benefit of
this PEP, making Python packaging easier and more reliable. In addition, the
authors envision other types of tools making use of this information; e.g.,
dependency analysis tools like Repology_, Dependabot_ and libraries.io_.


Rationale
=========

Prior art
---------

The R language has a `System Requirements for R packages
<https://github.com/rstudio/r-system-requirements>`__ with a central
registry that knows how to translate external dependency metadata to install
commands for package managers like ``apt-get``. This registry centralises the
mappings for a series of Linux distributions, and also Windows. macOS is not
present. The `"Rule Coverage" of its README
<https://github.com/rstudio/r-system-requirements/blob/7314012a48d38854c19f439e1c2d2e4b383fe7ea/README.md#rule-coverage>`__
used to show that this system improves the chance of success of building packages
from CRAN from source. Across all CRAN packages,
Ubuntu 18 improved from 78.1% to 95.8%, CentOS 7 from 77.8% to 93.7% and openSUSE
15.0 from 78.2% to 89.7%. The chance of success depends on how well the registry
is maintained, but the gain is significant: ~4x fewer packages fail to build on
Ubuntu and CentOS in a Docker container.

RPM-based distributions, like Fedora, can use a `rule-based implementation
<https://discuss.python.org/t/wanting-a-singular-packaging-tool-vision/21141/117>`__
(``NameConvertor``) in pyp2rpm_. The main rule is that the RPM name for a PyPI package is
``f"python-{pypi_package_name}"``. This seems to work quite well; there are a
few variants like Python version specific names, where the prefix contains the
Python major and minor version numbers (e.g. ``python311-`` instead of
``python-``).

Gentoo follows a similar approach to naming Python packages, using the ``dev-python/``
category and some `well-specified rules <https://projects.gentoo.org/python/guide/package-maintenance.html>`__.

Conda-forge has a more explicit name mapping, because the base names are the
same in conda-forge as on PyPI (e.g., ``numpy`` maps to ``numpy``), but there
are many exceptions because of both name collisions and renames (e.g., the PyPI
name for PyTorch is ``torch`` while in conda-forge it's ``pytorch``). There are
several name mappings efforts maintained by different teams. Conda-forge's infrastructure
generates one in `regro/cf-graph-countyfair <https://github.com/regro/cf-graph-countyfair/tree/master/mappings/pypi>`__.
Grayskull maintains `its own curated mapping <https://github.com/conda/grayskull/blob/main/grayskull/strategy/config.yaml>`__.
Prefix.dev created the `parselmouth mappings <https://github.com/prefix-dev/parselmouth>`__
to support conda and PyPI integrations in their tooling. A more complete overview of
their approaches, strengths and weaknesses can be found in
`conda/grayskull#564 <https://github.com/conda/grayskull/issues/564>`__.

The `OpenStack <https://www.openstack.org/>`__ ecosystem also needs to deal with
some mapping efforts. All of them focus on Linux distributions, exclusively.
`pkg-map <https://docs.openstack.org/diskimage-builder/latest/elements/pkg-map/README.html>`__
accompanies ``diskimage-builder`` and provides a file format where the user defines
arbitrary variable names and their corresponding names in the target distro
(Red Hat, Debian, OpenSUSE, etc). See `example for PyYAML <https://github.com/stbenjam/diskimage-builder/blob/5bc5f8aff3b40b1918ce72660f1dba38c3c4f27a/diskimage_builder/elements/svc-map/pkg-map#L4>`__.
`bindep <https://opendev.org/opendev/bindep>`__ defines a file ``bindep.txt``
(see `example <https://opendev.org/opendev/bindep/src/branch/master/bindep/tests/bindep.txt>`__)
where users can write down dependencies that are not installable from PyPI. The format is
line-based, with each line containing a dependency as found in the Debian ecosystem.
For other distributions, it offers a "filters" syntax between square brackets where users
can indicate other target platforms, optional dependencies and extras.

The need for mappings is also found in other ecosystems like `SageMath <https://github.com/sagemath/sage/issues/36356>`__,
but also by end-users themselves who want to install PyPI packages with their system
package manager of choice (`example StackOverflow question <https://unix.stackexchange.com/q/761371>`__).


Maintenance costs of name mappings
----------------------------------

The maintenance cost of external dependency mappings to a large number of packaging
ecosystems is potentially high. We choose to define the registry in such
a way that these mappings can be maintained by the target packaging ecosystems
themselves. Hence this system is opt-in for a given ecosystem,
and the associated maintenance costs are distributed. Some ecosystems
have such a name mapping already, because it's required for tools like pyp2rpm_
and Grayskull_ to work. In those cases, the additional maintenance costs of
connecting those mappings to a central registry are likely limited.

Generating package manager-specific install commands
----------------------------------------------------

Python package authors with external dependencies usually have installation
instructions for those external dependencies in their documentation. These
instructions are difficult to write and keep up-to-date, and are usually only
covering one or at most a handful of platforms. As an example, here are SciPy's
instructions for its external build dependencies (C/C++/Fortran compilers,
OpenBLAS, pkg-config):

- Debian/Ubuntu: ``sudo apt install -y gcc g++ gfortran libopenblas-dev liblapack-dev pkg-config python3-pip python3-dev``
- Fedora: ``sudo dnf install gcc-gfortran python3-devel openblas-devel lapack-devel pkgconfig``
- CentOS/RHEL: ``sudo yum install gcc-gfortran python3-devel openblas-devel lapack-devel pkgconfig``
- Arch Linux: ``sudo pacman -S gcc-fortran openblas pkgconf``
- Homebrew on macOS: ``brew install gfortran openblas pkg-config``

The package names vary a lot, and there are differences like some distros
splitting off headers and other build-time dependencies in a separate
``-dev``/``-devel`` package while others do not. With the registry in this PEP,
this could be made both more comprehensive and easier to maintain though a tool
command with semantics of *"show this ecosystem's preferred package manager
install command for all external dependencies"*. This may be done as a
standalone tool, or as a new subcommand in any Python development workflow tool
(e.g., Pip, Poetry, Hatch, PDM, uv).


Registry design
---------------

The mapping infrastructure should include the following components and properties:

- A central registry of PEP 725 identifiers (``dep:`` URLs), including at least the
  well-known generic and virtual identifiers considered canonical.
- A list of known ecosystems and their package managers, where ecosystem maintainers
  can register their name mapping(s).
- A standardized schema that defines how mappings should be structured.
- The above documents should be written in a structured, human-readable file format.
  As long as it can be validated with the corresponding JSON Schemas, they could be
  delivered as JSON, YAML, TOML and/or others.
- One central Python package for the central registry, list of ecosystems and known
  mappings.

On the client side, there should be:

- A way for the system to specify a default (e.g., the Python installation on Ubuntu
  could register ``apt`` as the default system package manager with the
  registry tool). It may also be left unspecified.
- A way for the user to specify the default and/or current system package manager.
  E.g., a user on Ubuntu may want either ``apt``, ``conda``, ``brew``  or ``spack``
  as their package manager of choice to provide external dependencies.


Specification
=============

Three schemas are proposed:

1. A central registry of known ``dep:`` identifiers, as introduced in PEP 725.
2. A list of known ecosystems and the location of their mappings.
3. The ecosystem-specific mappings of ``dep:`` identifiers to their
   corresponding ecosystem specifiers, plus details of their package manager(s).

The central registry defines which identifiers are recognized as canonical,
plus known aliases. Each entry MUST provide a valid ``dep:`` identifier in the
field ``id``, with an optional free form ``description`` text. Additionally
an entry MAY refer to another entry via its ``provides`` field, which takes
a string or a list of strings already defined as ``id`` in the registry. This is useful
for both aliases (e.g. ``dep:generic/arrow`` and ``dep:github/apache/arrow``) and
concrete implementations of a ``dep:virtual/`` entry (e.g. ``dep:generic/gcc``
would provide ``dep:virtual/compiler/c``). Entries without ``provides`` content
or, if populated, only with ``dep:virtual/`` identifiers, are considered
canonical. The ``provides`` field MUST NOT be present in ``dep:virtual/`` definitions.

Having a central registry enables client-side validation of the ``[external]``
table of any given project. Tools SHOULD disallow ``dep:`` identifiers
that are not included in the central registry and SHOULD recommend using the
canonical form instead of a secondary alias.

The list of known ecosystems assigns an identifier to each ecosystem and reports the
canonical location for its mapping. The mappings specify which ecosystem-specific
identifiers provide the canonical entries available in the central registry. Its
main content is a list of dictionaries, in which each entry consists of:

- an ``id`` field with the ``dep:`` canonical identifier.

- an optional free form ``description`` text.

- a ``specs`` field whose value MUST be one of:

  - a dictionary with three keys (``build``, ``host``, ``run``). The values
    MUST be a string or list of strings representing the ecosystem-specific package
    identifiers as needed as build-, host- and runtime dependencies (see PEP 725 for
    details on these definitions).

  - for convenience, a string or a list of strings are also accepted as a
    shorthand form. In this case, the identifier(s) will be used to populate
    the three categories mentioned in the item above.

  - an empty list, which is understood as the ecosystem not having packages to
    provide such dependency.

- a ``specs_from`` field whose value is a ``dep:`` identifier from which the ``specs``
  field will be imported. Either ``specs`` or ``specs_from`` MUST be present.

- an optional ``urls`` field whose value MUST be a URL, a list of URLs, or a
  dictionary that maps a string to a URL. This is useful to link to external
  resources that provide more information about the mapped packages.

Some examples from a hypothetical conda-forge mapping would include:

.. code-block:: js

  [
    {
      "id": "dep:generic/zlib",
      "description": "zlib data compression library for the next generation systems. From zlib-ng/zlib-ng.",
      "specs": "zlib-ng",  // Simplest form
      "urls": {
        "feedstock": "https://github.com/conda-forge/zlib-ng-feedstock"
      }
    },
    {
      "id": "dep:generic/libwebp",
      "description": "WebP image library. libwebp-base ships libraries; libwebp ships the binaries.",
      "specs": {  // expanded form with single spec per category
        "build": "libwebp",
        "host": "libwebp-base",
        "run": "libwebp"
      },
      "urls": {
        "feedstock": "https://github.com/conda-forge/libwebp-feedstock"
      }
    },
    {
      "id": "dep:generic/clang",
      "description": "Development headers and libraries for Clang",
      "specs": { // expanded form with specs list
        "build": [
          "clang",
          "clangxx"
        ],
        "host": [
          "clangdev"
        ],
        "run": [
          "clang",
          "clangxx",
          "clang-format",
          "clang-tools"
        ]
      },
      "urls": {
        "feedstock": "https://github.com/conda-forge/clangdev-feedstock"
      }
    },
  ]

The mappings MAY also specify another section ``package_managers``, reporting
which package managers are available in the ecosystem. This field MUST
take a list of dictionaries, with each of them reporting the following fields:

- ``name`` (string), usually the name of the package manager executable.
- ``install_command`` (list of strings), the command to run to install the mapped package(s).
- ``query_command`` (list of strings), the command to check if the mapped package(s)
  are already installed.
- ``requires_elevation`` (bool, ``install`` or ``query``): whether the associated commands require
  superuser permissions to run.
- ``version_operators``: a mapping of PEP 440 operator names to the relevant
  syntax for this package manager.

Details
-------

Three JSON Schema documents are provided to fully standardize the registries and mappings.

Central registry schema
^^^^^^^^^^^^^^^^^^^^^^^

The central registry is specified by the following
`JSON schema <https://github.com/jaimergp/external-metadata-mappings/blob/main/schemas/central-registry.schema.json>`__:

``$schema``
~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - $Schema
    * - Type
      - ``string``
    * - Description
      - URL of the definition list schema in use for the document.
    * - Required
      - False

``schema_version``
~~~~~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Schema Version
    * - Type
      - ``integer``
    * - Required
      - False

``definitions``
~~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Definitions
    * - Type
      - ``array``
    * - Description
      - List of ``dep:`` identifiers currently recognized.
    * - Required
      - True

Each entry in this list is defined as:

.. list-table::
    :header-rows: 1
    :widths: 20 25 40 15

    * - Field
      - Type
      - Description
      - Required
    * - ``id``
      - ``DepURLField`` (``string`` matching regex ``^dep:.+$``)
      - ``dep:`` identifier
      - True
    * - ``description``
      - ``string``
      - Free-form field to add some details about the package. Allows Markdown.
      - False
    * - ``provides``
      - ``DepURLField | list[DepURLField]``
      - List of identifiers this entry connects to.
        Useful to annotate aliases or virtual package implementations.
      - False
    * - ``urls``
      - ``AnyUrl | list[AnyUrl] | dict[NonEmptyString, AnyUrl]``
      - Hyperlinks to web locations that provide more information about the definition.
      - False

Known ecosystems schema
^^^^^^^^^^^^^^^^^^^^^^^

The known ecosystems list is specified by the following
`JSON Schema <https://github.com/jaimergp/external-metadata-mappings/blob/main/schemas/known-ecosystems.schema.json>`__:

``$schema``
~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - $Schema
    * - Type
      - ``string``
    * - Description
      - URL of the mappings schema in use for the document.
    * - Required
      - False

``schema_version``
~~~~~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Schema Version
    * - Type
      - ``integer``
    * - Required
      - False

``ecosystems``
~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Ecosystems
    * - Type
      - ``dict``
    * - Description
      - Ecosystems names and their corresponding details.
    * - Required
      - True

This dictionary maps non-empty string keys referring to the ecosystem identifiers
to a sub-dictionary defined as:

.. list-table::
    :header-rows: 1
    :widths: 20 25 40 15

    * - Key
      - Value type
      - Value description
      - Required
    * - ``Literal['mapping']``
      - ``AnyURL``
      - URL to the mapping for this ecosystem
      - True

Mappings schema
^^^^^^^^^^^^^^^

The mappings are specified by the following
`JSON Schema <https://github.com/jaimergp/external-metadata-mappings/blob/main/schemas/external-mapping.schema.json>`__:

``$schema``
~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - $Schema
    * - Type
      - ``string``
    * - Description
      - URL of the mappings schema in use for the document.
    * - Required
      - False

``schema_version``
~~~~~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Schema Version
    * - Type
      - ``integer``
    * - Required
      - False

``name``
~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Name
    * - Type
      - ``string``
    * - Description
      - Name of the schema
    * - Required
      - True

``description``
~~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Description
    * - Type
      - ``string | None``
    * - Description
      - Free-form field to add information this mapping. Allows
        Markdown.
    * - Required
      - False

``mappings``
~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Mappings
    * - Type
      - ``array``
    * - Description
      - List of ``dep:``-to-specs mappings.
    * - Required
      - True

Each entry in this list is defined as:

.. list-table::
    :header-rows: 1
    :widths: 20 25 40 15

    * - Field
      - Type
      - Description
      - Required
    * - ``id``
      - ``DepURLField`` (``string`` matching regex ``^dep:.+$``)
      - ``dep:`` identifier, as provided in the central registry
      - True
    * - ``description``
      - ``string``
      - Free-form field to add some details about the package. Allows Markdown.
      - False
    * - ``urls``
      - ``AnyUrl | list[AnyUrl] | dict[NonEmptyString, AnyUrl]``
      - Hyperlinks to web locations that provide more information about the definition.
      - False
    * - ``specs``
      - ``string | list[string] | dict[Literal['build', 'host', 'run'], string | list[string]]``
      - Ecosystem-specific identifiers for this package. The full form is a dictionary
        that maps the categories ``build``, ``host`` and ``run`` to their corresponding
        package identifiers. As a shorthand, a single string or a list of strings can be
        provided, in which case will be used to populate the three categories identically.
      - Either ``specs`` or ``specs_from`` MUST be present.
    * - ``specs_from``
      - ``DepURLField`` (``string`` matching regex ``^dep:.+$``)
      - Take specs from another mapping entry.
      - Either ``specs`` or ``specs_from`` MUST be present.
    * - ``extra``
      - ``dict[NonEmptyString, Any]``
      - Free-form key-value store for arbitrary metadata.
      - False

``package_managers``
~~~~~~~~~~~~~~~~~~~~

.. list-table::
    :widths: 25 75

    * - Title
      - Package Managers
    * - Type
      - ``array``
    * - Description
      - List of tools that can be used to install packages in this
        ecosystem.
    * - Required
      - True

Each entry in this list is defined as a dictionary with these fields:

.. list-table::
    :header-rows: 1
    :widths: 20 25 40 15

    * - Field
      - Type
      - Description
      - Required
    * - ``name``
      - ``string``
      - Short identifier for this package manager (usually the command name)
      - True
    * - ``install_command``
      - ``list[string]``
      - Command that must be used to install the given package(s). Each
        argument must be provided as a separate string, as in `subprocess.run`.
        Use `{}` as a placeholder where the package specs must be injected, if
        needed. If `{}` is not present, they will be added at the end.
      - True
    * - ``query_command``
      - ``list[string]``
      - Command to check whether a package is installed. Each argument must be
        provided as a separate string, as in `subprocess.run`. The `{}`
        placeholder will be replaced by a single package spec, if needed.
        Otherwise, the package specifier will be added at the end. An empty
        list means no query command is available for this package manager.
      - True
    * - ``requires_elevation``
      - ``bool | Literal['install', 'query']``
      - Whether the install and query commands require elevated permissions to
        run. Use ``True`` to require on all commands, ``False`` for none. ``install``
        and ``query`` can be used individually to only require elevation on one
        of them.
      - False
    * - ``version_operators``
      - ``dict[Literal['and', 'arbitrary', 'compatible', 'equal', 'greater_than_equal', 'greater_than', 'less_than_equal', 'less_than', 'not_equal', 'separator'],  string]``
      - Mapping of PEP440 version comparison operators to the syntax used in this
        package manager. If omitted, PEP 440 operators are used. If set to an empty
        dictionary, it means that the package manager (or ecosystem) doesn't support
        the notion of requesting particular package versions. The keys are ``and``,
        ``arbitrary``, ``compatible``, ``equal``, ``greater_than_equal``,
        ``greater_than``, ``less_than_equal``, ``less_than``, ``not_equal``, and
        ``separator``. Empty strings can be used as a value if that particular operator
        is not supported.
      - False


Examples
--------

The following repository provides examples of how these schemas would look like in real cases:

- `Central registry <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/registry.json>`__.
- `Known ecosystems <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/known-ecosystems.json>`__.
- Mappings:
  - `Arch-linux <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/arch-linux.mapping.json>`__.
  - `Chocolatey <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/chocolatey.mapping.json>`__.
  - `Conan <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/conan.mapping.json>`__.
  - `Conda-forge <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/conda-forge.mapping.json>`__.
  - `Fedora <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/fedora.mapping.json>`__.
  - `Gentoo <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/gentoo.mapping.json>`__.
  - `Homebrew <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/homebrew.mapping.json>`__.
  - `Nix <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/nix.mapping.json>`__.
  - `PyPI <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/pypi.mapping.json>`__.
  - `Scoop <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/scoop.mapping.json>`__.
  - `Spack <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/spack.mapping.json>`__.
  - `Ubuntu <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/ubuntu.mapping.json>`__.
  - `Vcpkg <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/vcpkg.mapping.json>`__.
  - `Winget <https://github.com/jaimergp/external-metadata-mappings/blob/main/data/winget.mapping.json>`__.

pyproject-external CLI
^^^^^^^^^^^^^^^^^^^^^^

The following examples illustrate how the name mapping mechanism may be used.
They use the CLI implemented as part of the ``pyproject-external`` package.

Say we have cloned the source of a Python package named ``my-cxx-pkg`` with a
single extension module, implemented in C++, linking to ``zlib``, using ``pybind11``,
plus ``meson-python`` as the build backend:

.. code:: toml

    [build-system]
    build-backend = 'mesonpy'
    requires = [
      "meson-python>=0.13.1",
      "pybind11>=2.10.4",
    ]

    [external]
    build-requires = [
      "dep:virtual/compiler/cxx",
    ]
    host-requires = [
      "dep:generic/zlib",
    ]

With complete name mappings for ``apt`` on Ubuntu, this may then show the
following:

.. code:: bash

    # show all external dependencies as dep: URLs
    $ python -m pyproject_external show .
    [external]
    build-requires = [
        "dep:virtual/compiler/cxx",
    ]
    host-requires = [
        "dep:generic/zlib",
    ]

    # show all external dependencies, but mapped to the autodetected ecosystem
    $ python -m pyproject_external show --output=mapped .
    [external]
    build_requires = [
        "g++",
        "python3",
    ]
    host_requires = [
        "zlib1g",
        "zlib1g-dev",
    ]

    # show how to install external dependencies
    $ python -m pyproject_external show --output=command .
    sudo apt install --yes g++ zlib1g zlib1g-dev python3

We have not yet run those install commands, so the external dependency may be
missing. If we get a build failure, the output may look like:

.. code::

    $ pip install .
    ...
    √ó Encountered error while generating package metadata.
    ‚ï∞‚îÄ> See above for output.

    note: This is an issue with the package mentioned above, not pip.

    This package has the following external dependencies, if those are missing
    on your system they are likely to be the cause of this build failure:

      dep:virtual/compiler/cxx
      dep:generic/zlib

If Pip has implemented support for querying the name mapping registry, the end
of that message could improve to:

.. code:: bash

    The following external dependencies are needed to install the package
    mentioned above. You may need to install them with `apt`:

      g++
      zlib1g
      zlib1g-dev

If the user wants to use conda packages and the ``mamba`` package manager to
install external dependencies, they may specify that in their
``~/.config/pyproject-external/config.toml`` file:

.. code:: toml

    preferred_package_manager = "mamba"

This will then change the output of ``pyproject-external``:

.. code:: bash

    $ python -m pyproject_external show --output command .
    mamba install --yes --channel=conda-forge --channel-priority=strict cxx-compiler zlib python


The ``pyproject-external`` CLI also provides a simple way to perform
``[external]`` table validation:

.. code-block:: bash

    $ python -m pyproject_external show --validate grpcio-1.71.0.tar.gz
    WARNING  Dep URL 'dep:virtual/compiler/cpp' is not recognized in the
    central registry. Did you mean any of ['dep:virtual/compiler/c',
    'dep:virtual/compiler/cxx', 'dep:virtual/compiler/cuda',
    'dep:virtual/compiler/go', 'dep:virtual/compiler/c-sharp']?
    [external]
    build-requires = [
        "dep:virtual/compiler/c",
        "dep:virtual/compiler/cpp",
    ]


pyproject-external API
^^^^^^^^^^^^^^^^^^^^^^

The ``pyproject-external`` Python API also allows users to do these operations programmatically:

.. code-block:: python

    >>> from pyproject_external import External
    >>> external = External.from_pyproject_data(
          {
            "external": {
              "build-requires": [
                "dep:virtual/compiler/c",
                "dep:virtual/compiler/cpp",
              ]
            }
          }
        )
    >>> external.validate()
    Dep URL 'dep:virtual/compiler/cpp' is not recognized in the central registry. Did you
    mean any of ['dep:virtual/compiler/c', 'dep:virtual/compiler/cxx',
    'dep:virtual/compiler/cuda', 'dep:virtual/compiler/go', 'dep:virtual/compiler/c-sharp']?
    >>> external = External.from_pyproject_data(
          {
            "external": {
              "build-requires": [
                "dep:virtual/compiler/c",
                "dep:virtual/compiler/cxx",  # fixed
              ]
            }
          }
        )
    >>> external.validate()
    >>> external.to_dict()
    {'external': {'build_requires': ['dep:virtual/compiler/c', 'dep:virtual/compiler/cxx']}}
    >>> from pyproject_external import detect_ecosystem_and_package_manager
    >>> ecosystem, package_manager = detect_ecosystem_and_package_manager()
    >>> ecosystem
    'conda-forge'
    >>> package_manager
    'pixi'
    >>> external.to_dict(mapped_for=ecosystem, package_manager=package_manager)
    {'external': {'build_requires': ['c-compiler', 'cxx-compiler', 'python']}}
    >>> external.install_command(ecosystem, package_manager=package_manager)
    ['pixi', 'add', 'c-compiler', 'cxx-compiler', 'python']

Grayskull
^^^^^^^^^

A prototype proof of concept implementation was contributed to Grayskull, a conda recipe generator for
Python packages, via `conda/grayskull#518 <https://github.com/conda/grayskull/pull/518>`__.

In order to use the name mappings for the recipe generator of our package, we
can now run Grayskull_:

.. code::

    $ grayskull pypi my-cxx-pkg
    #### Initializing recipe for my-cxx-pkg (pypi) ####

    Recovering metadata from pypi...
    Starting the download of the sdist package my-cxx-pkg
    my-cxx-pkg 100% Time:  0:00:10   5.3 MiB/s|###########|
    Checking for pyproject.toml
    ...

    Build requirements:
      - python                                 # [build_platform != target_platform]
      - cross-python_{{ target_platform }}     # [build_platform != target_platform]
      - meson-python >= 0.13.1                 # [build_platform != target_platform]
      - pybind11 >= 2.10.4                     # [build_platform != target_platform]
      - ninja                                  # [build_platform != target_platform]
      - libboost-devel                         # [build_platform != target_platform]
      - {{ compiler('cxx') }}
    Host requirements:
      - python
      - meson-python >=0.13.1
      - pybind11 >=2.10.4
      - ninja
      - libboost-devel
    Run requirements:
      - python

    #### Recipe generated on /path/to/recipe/dir for my-cxx-pkg ####



Backwards Compatibility
=======================

There is no impact on backwards compatibility.


Security Implications
=====================

TBD.

.. JRG: Something about arbitrary command execution, untrusted mappings,
   and superuser permissions being required in some systems.

How to Teach This
=================

There are at least four audiences that need to learn a workflow here.

1. Python package maintainers wishing to express an external dependency.
2. Packaging ecosystem maintainers, who are responsible for keeping the
   mapping for their ecosystem current.
3. Core registry maintainers, who are responsible for curating the central
   repository of ``dep:`` identifiers and descriptors.
4. End users of packages that have external dependency metadata.

Python package maintainer usage
-------------------------------

A package maintainer's responsibility is to decide the ``dep:`` identifier that best
represents the external dependency that their package needs. Their task
consists of:

1. Understanding the nature of their dependency. Do they only need runtime
   libraries, or do they need development packages for build-time concerns?
   This understanding feeds into PEP 725, which specifies the expression of
   these dependencies in metadata.
2. Looking up the ``dep:`` identifier. This can either mean knowing the name of the package
   in their package ecosystem, and then inverse-mapping that to the ``dep:`` identifier, or
   it can mean looking up the ``dep:`` identifier directly.
3. When a package maintainer does not find an appropriate mapping, they should look
   for a fitting ``dep:`` identifier. It can be the case that although a ``dep:`` identifier is registered, not every
   package ecosystem has a corresponding mapping. If no appropriate ``dep:`` identifier exists,
   the package maintainer may consider submitting a new ``dep:`` identifier to the central registry.

A prototype interactive mappings browser that showcases this workflow is available at
`external-metadata-mappings.streamlit.app <https://external-metadata-mappings.streamlit.app/>`__.

An overall workflow diagram might look like this:

.. mermaid::

   flowchart TD
     A[Python package author with new external dependency] --> |Looks in| B(``dep:`` identifier/description collection)
     B --> | Find ``dep:`` identifier OK | E(Add ``dep:`` identifier to pyproject.toml)
     A --> | Looks in | C(Ecosystem mapping file)
     C --> | Finds familiar ecosystem package name | D(Inverse map ecosystem package name to ``dep:`` identifier)
     D --> | Mapping exists | E
     B --> | ``dep:`` identifier not found | F(Submit identifier proposal to ``dep:`` identifier/description collection)
     F --> | Accepted | G(Mapping maintainers notified of missing ``dep:`` identifier mappings)
     D --> | Mapping missing. User looks in ``dep:`` identifier collection. | B
     B --> | Was mapping missing? | H(User may contribute entry to mapping)

Package ecosystem maintainers usage
-----------------------------------

Any packages that express a ``dep:`` identifier that does not have a mapping in a given package
ecosystem might not be able to provide tailored error messages and other UX affordances for end users.
It is thus recommended that each package ecosystem maintain their mappings. Key to this will
be automation. Some ideas for opt-in automation are:

- Alert mapping maintainers whenever a new ``dep:`` identifier is added to the registry (maybe noisy).
- Provide tools that allow maintainers to diff their mappings to the registry contents to
  quickly identify missing entries.
- Provide automated tooling that submits PRs to known mapping locations, such that maintainers
  need only fill in the ecosystem package name.
- Provide status for each ``dep:`` identifier, to readily identify which ``dep:`` identifiers need attention.

This maintenance is likely to involve a lot of work to establish the initial mapping, but ideally become small
on an ongoing basis.


Central ``dep:`` identifier registry maintainers
------------------------------------------------

Central ``dep:`` identifier registry maintainers curate the collection of
``dep:`` identifiers. These contributors need to be able to refer to clearly
defined rules for when a new ``dep:`` identifier can be defined. It is
undesirable to be loose with canonical ``dep:`` identifier definitions, because
each definition implies maintenance in the mappings in many other places.

The ``provides`` key mechanism offer ways to maintain aliases, so hopefully a
compromise of flexibility and strictness can be found easily. Particular attention
must be put to deciding which of the aliases will be the canonical form, though,
especially when it comes to dependencies where a number of synonyms are commonly
used. This does not apply to ``dep:virtual/*`` identifiers, where a single canonical
form is proposed and no additional aliases are allowed.

Having client-side validation when the Python project is being packaged and/or uploaded
to PyPI may help keep the maintenance efforts contained, since end-users can be pointed
to the recommended identifiers.

End user package consumers
--------------------------

There will be no change in user experience by default. End users do not need to know about
this mechanism unless they opt in, which they may want to do to, for example, reduce their
bandwidth and disk space usage. This is particularly true if the user only relies on wheels,
since the only impact will be driven by external runtime dependencies.

If they do opt-in, in an ideal case these package install commands can be done transparently,
and the user experience remains unchanged. There are several foreseeable issues that will arise,
though:

* A mapping does not exist for the user's desired package ecosystem.
* A user does not have permissions to run the install commands provided by our
  tool (e.g. system Python users).

These issues might impact the user experience with untailored error messages for the chosen
ecosystem, permission errors reports, and so on.

Reference Implementation
========================

A reference implementation should include three components:

1. A central registry that captures at a minimum a ``dep:`` identifier and its description. This registry MUST
   NOT contain specifics of package ecosystem mappings.
2. A standard specification for a collection of mappings. JSON Schema is widely used for schema
   in many text editors, and would be a natural choice for expression of the standard specification.
3. An implementation of (2), providing mappings from the contents of the central
   registry to the ecosystem-specific package names.

For (1), the JSON Schema is defined at https://github.com/jaimergp/external-metadata-mappings/blob/main/schemas/central-registry.schema.json.
An example registry can be found at https://github.com/jaimergp/external-metadata-mappings/blob/main/data/registry.json.
For (2), the JSON Schema is defined at https://github.com/jaimergp/external-metadata-mappings/blob/main/schemas/external-mapping.schema.json.
For (3), a collection of example mappings for a sample of packages can be found at https://github.com/jaimergp/external-metadata-mappings/tree/main/data.

The JSON Schemas are created with `this Pydantic model <https://github.com/jaimergp/external-metadata-mappings/blob/main/schemas/schema.py>`__.

The reference CLI and Python API to consume the different JSON documents and ``[external]`` tables
can be found in `pyproject-external <https://github.com/jaimergp/pyproject-external>`__.

Rejected Ideas
==============

Centralized mappings governed by the same body
----------------------------------------------

While a central authority for the registry is useful, the maintenance burden
of handling the mappings for multiple ecosystems is unfeasible at the scale of PyPI.
Hence, we propose that the central authority only governs the central registry and
the list of known ecosystems, while the maintenance of the mappings themselves is handled
by the target ecosystems. More details are given in Rationale and Governance.

Allowing ecosystem-specific variants of packages
------------------------------------------------

Some ecosystems have their own variants of known packages; e.g. Debian's
``libsymspg2-dev``. While an identifier such as ``dep:debian/libsymspg2-dev``
is syntactically valid, the central registry should not recognize it as a
well-known identifier, preferring its ``generic`` counterpart instead. Users
may still choose to use it, but tools may warn about it and suggest using the
generic one. This is meant to encourage ecosystem agnostic metadata whenever
possible to facilitate adoption across platforms and operating systems.

Adding more package metadata to the central registry
----------------------------------------------------

A central registry should only contain a list of ``dep:`` URLs and a
minimal set of metadata fields to facilitate its identification (a free-form
text description, and one or more URLs to relevant locations).

These fields should be enough to identify the project home,
where that extra metadata can be obtained (e.g. the repository URL will likely
include details about authorship and licensing). Also, those details may change
over the lifetime of the project, and keeping them up-to-date would increase the
maintenance burden on the governance body.

Hence, we choose to leave these details out of the central registry, and instead
suggest external contributors to maintain their own mappings where they can
annotate the identifiers with extra metadata via the free-form ``extra`` field.

Mapping PyPI projects to repackaged counterparts in target ecosystems
---------------------------------------------------------------------

It is common that other ecosystems redistribute Python projects with their own
packaging system. While this is required for packages with compiled extensions, it
is theoretically unnecessary for pure Python wheels; the only need for this seems to
be metadata translation. See https://discuss.python.org/t/wanting-a-singular-packaging-tool-vision/21141/68,
https://discuss.python.org/t/wanting-a-singular-packaging-tool-vision/21141/103 and
https://github.com/spack/spack/issues/28282#issuecomment-1562178367 for examples of
discussions in this direction.

The proposals in this PEP do not consider PyPI -> *ecosystem* mappings, but
the same schemas can be repurposed to that end. After all, it is trivial to build a PURL or
``dep:`` URL from a PyPI name (e.g. ``numpy`` becomes ``pkg:pypi/numpy``). A hypothetical
mapping maintainer could annotate their repackaging efforts with the source PURL identifier,
and then use that metadata to generate compatible mappings, such as:

```json
{
  "$schema": "https://raw.githubusercontent.com/jaimergp/external-metadata-mappings/main/schemas/external-mapping.schema.json",
  "schema_version": 1,
  "name": "PyPI packages in Ubuntu 24.04",
  "description": "PyPI mapping for the Ubuntu 24.04 LTS (Noble) distro",
  "mappings": [
    {
      "id": "dep:pypi/numpy",
      "description": "The fundamental package for scientific computing with Python",
      "specs": ["python3-numpy"],
      "urls": {
        "home": "https://numpy.org/"
      }
    }
  ]
}
```

Such a mapping would allow downstream redistribution efforts to focus on the
compiled packages and instead delegate pure wheels to Python packaging
solutions directly.


Open Issues
===========

References
==========

- https://github.com/jaimergp/pyproject-external
- https://github.com/rgommers/external-deps-build
- https://github.com/jaimergp/external-metadata-mappings
- https://github.com/conda/grayskull/pull/518

Copyright
=========

This document is placed in the public domain or under the
CC0-1.0-Universal license, whichever is more permissive.


.. _PyPI: https://pypi.org
.. _core metadata: https://packaging.python.org/specifications/core-metadata/
.. _setuptools: https://setuptools.readthedocs.io/
.. _setuptools metadata: https://setuptools.readthedocs.io/en/latest/setuptools.html#metadata
.. _SPDX: https://spdx.dev/
.. _PURL: https://github.com/package-url/purl-spec/
.. _vers: https://github.com/package-url/purl-spec/blob/version-range-spec/VERSION-RANGE-SPEC.rst
.. _vers implementation for PURL: https://github.com/package-url/purl-spec/pull/139
.. _pyp2rpm: https://github.com/fedora-python/pyp2rpm
.. _Grayskull: https://github.com/conda/grayskull
.. _dh_python: https://www.debian.org/doc/packaging-manuals/python-policy/index.html#dh-python
.. _Repology: https://repology.org/
.. _Dependabot: https://github.com/dependabot
.. _libraries.io: https://libraries.io/
.. _crossenv: https://github.com/benfogle/crossenv
.. _Python Packaging User Guide: https://packaging.python.org
.. _pyOpenSci Python Open Source Package Development Guide: https://www.pyopensci.org/python-package-guide/
.. _Scikit-HEP packaging guide: https://scikit-hep.org/developer/packaging


..
   Local Variables:
   mode: indented-text
   indent-tabs-mode: nil
   sentence-end-double-space: t
   fill-column: 70
   coding: utf-8
   End:
